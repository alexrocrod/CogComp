\documentclass[a4paper, 11pt]{article}
\usepackage{geometry}
\usepackage{indentfirst}
\usepackage{setspace}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{caption}
\usepackage{indentfirst}
\setlength{\parindent}{20pt}
\usepackage{amssymb}
\usepackage{float}
\usepackage{subcaption}

\graphicspath{ {./images/} }
\geometry{left=2.5cm, right=2.5cm, top=2.5cm, bottom=2.5cm}

\begin{document}	
	\title{Project \# 3. Multimedia Coding }
	\author{{\small Alexandre Rodrigues (2039952)}}
	\date{\today}
	\maketitle
	
	\section{Introduction}
		This report is dedicated to explain the usage of the LBG-split algorithm and how to implement it.
		The Linde-Buzo-Gray algorithm is a lossy coding technique that uses vector quantization, meaning that a block of input samples is processed together.
		We will understand what affects the final signal to noise ratio: codevector length $ L $, rate $ R $, training set used, etc..
	
	\section{Technical Approach}
		Each vector of size $ L $ samples can be defined as
		\begin{equation}
			\mathbf{x} = [x_1, x_2, \ldots, x_L], x \in \mathbb{R}^L
		\end{equation}
		where $x_i, i=1,2,\ldots,L$ are input samples. 
		Using $\mathbf{y}_i $ as a codevector, 
		\begin{equation}
			B =  \{\mathbf{y}_1, \mathbf{y}_2, \ldots, \mathbf{y}_K\}
		\end{equation} 
		is the set of reconstruction levels, i.e. the codebook, of size $ K $.
		The decision cells will be
		\begin{align}
			& I_i \subseteq R^L, i = 1, 2, \ldots, K \\
			& I_i\ \cap \ I_j = \O ,\ \forall i \neq j \\
			& \bigcup^K_{i=1} I_i = \mathbb{R}^L
		\end{align} 
		
		The quantization procedure aims to minimize the distortion $ D $, defined as 
		\begin{equation}
			D = \mathbb{E} [||\mathbf{x}-Q(\mathbf{x})||^2],
		\end{equation} 
		where $ Q(\mathbf{x}) = \mathbf{y}_i $ maps the input vector $ \mathbf{x} $ to $\mathbf{y}_i \in B$ when $\mathbf{x} \in I_i $.
		The rate $R$ is the number of bits used to quantize each component of the codevector
		\begin{equation}
			R = \frac{1}{L}\lceil log_2K\rceil,
			\label{eq:rate}
		\end{equation} 
		where $ K $ is the codebook size, in this case a power of $ 2 $.
		
		Optimality is achieved when the following conditions are fulfilled:
		\begin{itemize}
			\item Nearest Neighbour Condition: $ I_i = \{\mathbf{x} $  if $||\mathbf{x} - \mathbf{y}_i||_2^2 \leq  ||\mathbf{x} - \mathbf{y}_j||_2^2, j\neq i\}, i=1,2,\ldots,K $;
			\item Centroid Condition $y_i = \frac{\int_{I_i} \mathbf{x} f_{\mathbf{x}}(\mathbf{x})d\mathbf{x}}{\int_{I_i} f_{\mathbf{x}}(\mathbf{x})d\mathbf{x}} $.
		\end{itemize}
		These conditions will be used by the LBG algorithm to iteratively optimize the codebook.
			
		\subsection{LBG}
			Since we do not know the probability distribution function of the input data $ f_{\mathbf{x}}(\mathbf{x}) $ we can use a training set
			\begin{equation}
				T = {\mathbf{x}_1,\ldots,\mathbf{x}_N}
			\end{equation},
			where $N$ should be considerably larger than the codebook size $ K $, $  N \ge 500K $ for this work.
			
			The algorithm can then be defined as:
			\begin{enumerate}
				\item Initial codebook and distortion: 
				$$ \{\mathbf{y}_1^{0}, \mathbf{y}_2^{0}, \ldots, \mathbf{y}_K^{0}\}\ ,\  D^{0} \gets \infty $$
				\item Find the optimal decision cells:
				$$ I_i^{new} \gets \{\mathbf{x} \in T \ if \ ||\mathbf{x} - \mathbf{y}_i^{prev}||_2^2 \leq  ||\mathbf{x} - \mathbf{y}_j^{prev}||_2^2, j\neq i\} $$
				\item Find the new codebook as the average of training set vectors in that partition: 
				$$ \mathbf{y}_i^{new} \gets \frac{1}{I_i^{new}} \sum_{\mathbf{x} \in I_i^{new}} \mathbf{x}, i=1,2,\ldots,K$$
				\item Compute the average distortion:
				$$ D^{new} \gets \frac{1}{N} \sum_{\mathbf{x} \in T} ||\mathbf{x} - Q(\mathbf{x})||^2_2$$ 
				\item Terminate if relative evolution of distortion is minimal:
				$$ \frac{ D^{old}- D^{new}}{D^{new}} < \epsilon$$
			\end{enumerate}
		
		\subsection{Split approach}
				This approach is based on starting a codebook as 
				\begin{equation}
					\{(1-\epsilon)y_{avg}, (1+\epsilon)y_{avg}\},
				\end{equation}
				where $ y_{avg} $ is the average of the vectors in the training set.
				The LBG algorithm is then applied to this codebook.
				The returning optimized codebook is split in the same way, i.e.
				\begin{equation}
					\{(1-\epsilon)y_i, (1+\epsilon)y_i, \ldots, (1-\epsilon)y_N, (1+\epsilon)y_N \}, 
				\end{equation}
				This implies that the codebook size will double in each iteration until we get the desired size K, $ N=2,4,8, \ldots,K $.			
		
	
	\section{Results}
		There were several tests made to fully understand the performance of this method.
		
		\subsection{Important Parameters}
			As required there are 4 scenarios
			\begin{table}[H]
				\centering
				\begin{tabular}{c|c|c}
					\textbf{L} 		& \textbf{R} 	& \textbf{K} 	\\ \hline
					$ 2 $			& $ 2 $ 		& $ 16 $	  	\\ \hline
					$ 2 $			& $ 4 $ 	  	& $ 256 $ 		\\ \hline	
					$ 4 $			& $ 1 $ 		& $ 16 $ 		\\ \hline	
					$ 4 $			& $ 2 $			& $	256 $ 		\\
				\end{tabular}
				\caption{Scenarios}
				\label{table:Scenarios}
			\end{table}
			where $ K $ is the codebook size, from equation \ref{eq:rate},
			\begin{equation}
				K = 2^{RL}.
			\end{equation} 
		
		
		\subsection{Training Sets}
			There 3 different training sets used:
			\begin{itemize}
				\item All audio files from the given dataset;
				\item Only the "Say Nada" song;
				\item All audio files and various popular songs.
			\end{itemize}
				
			Each training set was limited in size. 
			For each file I extracted the middle part to result in the following relative size ($ N/K $).
				
			\begin{table}[H]
				\centering
				\begin{tabular}{c|c|c}
					\textbf{Training set} & \textbf{$ N/K, L = 2 $} 	& \textbf{$ N/K, L = 4 $} \\ \hline
					All Audio 			& $ 1250 $ 					& $ 625 $	 			 \\ \hline
					Say Nada			& $ 1000 $ 				  	& $ 500 $ \\ \hline	
					All Music and Audio & $ 4844 $					& $	2422 $ \\
				\end{tabular}
				\caption{Relative Sizes of each Training Set}
				\label{table:TrainSets}
			\end{table}
			
			These sizes allowed fast enough codebook computation.
			Having training sets with and without including the encoding objects will benefit our comparison and possible conclusions.
				
		\subsection{Training Performance}
		
			The tests were made using $ \epsilon = 0.01 $.
			\begin{table}[H]
				\centering
				\begin{tabular}{c|c|c|c|c}
					\textbf{Training set} & \textbf{$ L=2, R=2 $} 	& \textbf{$ L=2, R=4 $}	&  \textbf{$ L=4, R=1 $}	& \textbf{$ L=4, R=2 $} \\ \hline
					All Audio 			& $ 1.51 \times 10^{5} $ 	& $ 3.53 \times 10^{5} $& $4.48 \times 10^{5} $ 	& $ 3.15 \times 10^{6} $ \\ \hline
					Music: Say Nada		& $ 4.36 \times 10^{6} $ 	& $ 3.71 \times 10^{6} $& $ 3.31 \times 10^{7} $  	& $ 2.70 \times 10^{7} $ \\ \hline
					All Music and Audio & $ 2.47 \times 10^{6} $	& $	1.93 \times 10^{6}$	& $ 9.70 \times 10^{6} $	& $	1.42 \times 10^{7} $ \\
				\end{tabular}
				\caption{Distortion for each training set and parameters}
				\label{table:TrainDist}
			\end{table}
			
			\begin{table}[H]
				\centering
				\begin{tabular}{c|c|c|c|c}
					\textbf{Training set}	 	& \textbf{$ L=2, R=2 $} 	& \textbf{$ L=2, R=4 $}	&  \textbf{$ L=4, R=1 $}	& \textbf{$ L=4, R=2 $} \\ \hline
					All Audio 					& $ 1.29 s $ 	& $ 179.09 s $	& $ 0.45 s $ 	& $ 86.02 5 s $	\\ \hline
					Music: Say Nada				& $ 0.75 s $	& $ 114.41 s $	& $ 0.47 s $ 	& $ 55.81 s $	\\ \hline
					All Music and Audio 	& $ 2.57 s $	& $	556.13 s $	& $ 1.21 s $	& $	266.74 s $	\\
				\end{tabular}
				\caption{Training time for each training set and parameters}
				\label{table:TrainTime}
			\end{table}
		
			We can see that ($ L=4, K=1 $) is clearly the fastest training scenario.
			The training time is mostly dependent on the value of $ R $.
			The distortion is noticeably larger for $ L = 4 $.
			
		\subsection{Encoding Performance}
			We will discuss performance regarding a music file form the DataSet (\texttt{70mono.wav}), various popular musics and a speech file from the DataSet (\texttt{49mono.wav}).
			In summary I got the following results:
			
			\begin{table}[H]
				\centering
				\begin{tabular}{c|c|c|c|c}
					\textbf{Encoded}	& \textbf{$ L=2, R=2 $} 	& \textbf{$ L=2, R=4 $}	&  \textbf{$ L=4, R=1 $}	& \textbf{$ L=4, R=2 $} \\ \hline
					Audio 70				& $ 1.50 s $ 	& $ 17.81 s $	& $ 0.74 s $ 	& $ 10.24 s $	\\ \hline
					Average Music			& $ 13.44 s $	& $ 188.31 s $	& $ 6.78 s $ 	& $ 95.41 s $	\\ \hline	
					Worst Case				& $ 18.02 s $	& $	137.08 s $	& $ 8.24 s $	& $	118.51 s $	\\ \hline
					Best Case				& $ 9.00 s $	& $	253.91 s $	& $ 4.63 s $	& $	70.26 s $	\\ \hline
					Audio 49				& $ 1.38 s $	& $	18.78 s $	& $ 0.79 s $	& $	9.73 s $	\\
				\end{tabular}
				\caption{Time for each encoding object and parameters}
				\label{table:EncodeTime}
			\end{table}
			There is no noticeable difference between using the different training sets.
			The music files clearly take more time to encode, this can be mostly due to the duration of the audio clip being larger.
			Both speech and music audio files from the dataset have similar encoding time due to their reduced duration.
			
			\begin{table}[H]
				\centering
				\begin{tabular}{c|c|c|c|c}
					\textbf{Encoded} & \textbf{$ L=2, R=2 $} 	& \textbf{$ L=2, R=4 $}	&  \textbf{$ L=4, R=1 $}	& \textbf{$ L=4, R=2 $} \\ \hline
					70mono			& $ 2.94 \times 10^{5} $ 	& $ 2.81 \times 10^{4} $& $ 6.32 \times 10^{5} $ 	& $ 7.51 \times 10^{4} $ \\ \hline
					Average Music	& $ 3.40 \times 10^{6} $ 	& $ 3.35 \times 10^{5} $& $ 4.38 \times 10^{6} $  	& $ 7.30 \times 10^{5} $ \\ \hline	
					Worst Case 		& $ 1.53 \times 10^{7} $	& $	1.95 \times 10^{6} $& $ 1.51 \times 10^{7} $	& $ 2.85 \times 10^6 $ \\ \hline
					Best Case 		& $ 3.66 \times 10^{5} $	& $ 2.21 \times 10^{4} $& $ 6.90 \times 10^{5} $ 	& $	1.99 \times 10^5 $ \\ \hline
					Audio 49		& $ 3.42 \times 10^{5} $	& $ 3.48 \times 10^{4} $& $ 7.61 \times 10^{5} $ 	& $ 1.10 \times 10^{5} $	\\
				\end{tabular}
				\caption{Distortion for each encoding object and parameters}
				\label{table:EncodeDist}
			\end{table}		
			Distortion is larger for the music files which can also be due to their larger duration.		
			
			\begin{table}[H]
				\centering
				\begin{tabular}{c|c|c|c|c}
					\textbf{Encoded} 	& \textbf{$ L=2, R=2 $} 	& \textbf{$ L=2, R=4 $}	&  \textbf{$ L=4, R=1 $}	& \textbf{$ L=4, R=2 $} \\ \hline
					Audio 70			& $ 12.55 $ 	& $  23.17 $	& $ 10.10 $		& $ 18.33 $ 	\\ \hline
					Average Music		& $ 13.83 $ 	& $  24.67  $	& $ 11.80 $  	& $ 19.68 $ 	\\ \hline	
					Worst Case 			& $ 8.74 $		& $	 17.54 $	& $ 8.00 $		& $ 15.15  $ 	\\ \hline
					Best Case 			& $ 17.01 $		& $ 27.86 $		& $ 16.60 $ 	& $	22.99  $ 	\\ \hline
					Audio 49 			& $ 11.69 $		& $ 21.87  $	& $ 8.58 $ 		& $	16.64  $ 	\\
				\end{tabular}
				\caption{SNR(dB) for each encoding object and parameters}
				\label{table:EncodeSNR}
			\end{table}
		
		The best values of Signal to Noise Ratio (SNR) are for ($ L=2, R=4 $), which shows the relevance of $R$ regarding SNR.
		There are significant differences regarding the training set used.
		
		\begin{table}[H]
			\centering
			\begin{tabular}{c|c|c|c|c}
				\textbf{Training Set} 		& \textbf{$ L=2, R=2 $} 	& \textbf{$ L=2, R=4 $}	&  \textbf{$ L=4, R=1 $}	& \textbf{$ L=4, R=2 $} \\ \hline
				All Audio 					& $ 11.26 $ 	& $ 21.45 $		& $ 10.24 $ 	& $ 17.79 $	\\ \hline
				Music: Say Nada				& $ 13.22 $		& $ 25.01 $		& $ 10.21 $ 	& $ 19.57 $	\\ \hline
				All Music and Audio 	& $ 15.86 $		& $	26.11 $		& $ 13.31 $		& $	20.22 $	\\
			\end{tabular}
			\caption{Average SNR(dB) for each training set and parameters}
			\label{table:EncodeSNRT}
		\end{table}
		
		The "All Music and Audio " training set is clearly superior in SNR, this may be due to including all encoding signals I tested with.
		
		\subsection{Original vs Final Audio Signal}
			In this subsection we will compare the original signal to the final signal, i.e. after encoding and decoding.
			We will show the results for the audio file 49.
			The other audio files got similar results. 
			All these results are from the "All Audio" training set, others training sets produced comparable results in most cases.
			
			\begin{figure}[H]
				\begin{subfigure}{.24\textwidth}
					\centering
					\includegraphics[width=.99\linewidth]{img4/49_2_2_100.png}  
					\caption{L=2, R=2}
					\label{fig:sub-first}
				\end{subfigure}
				\begin{subfigure}{.24\textwidth}
					\centering
					\includegraphics[width=.99\linewidth]{img4/49_2_4_100.png}  
					\caption{L=2, R=4}
					\label{fig:sub-second}
				\end{subfigure}
				\begin{subfigure}{.24\textwidth}
					\centering
					\includegraphics[width=.99\linewidth]{img4/49_4_1_100.png}  
					\caption{L=4, R=1}
					\label{fig:sub-third}
				\end{subfigure}
				\begin{subfigure}{.24\textwidth}
					\centering
					\includegraphics[width=.99\linewidth]{img4/49_4_2_100.png}  
					\caption{L=4, R=2}
					\label{fig:sub-fourth}
				\end{subfigure}
				\caption{Final vs Original signal extract for audio file 49}
				\label{fig:fig49}
			\end{figure}
			For $ K=256 $, i.e. ($ L=2,R=4 $) and ($ L=4,R=2 $), there is a better correspondence of the encoded signal to the original.
			For $ K = 16 $, one can notice differences in the lows and highs of the original signal.
			
		\subsection{Codebooks trained on All Audio}
			As an example of the codebooks computed we will see how adequate the codebook is when based on the "All Audio" training set for $ L=2 $ and $ R=2,4 $.
			\begin{figure}[H]
				\begin{subfigure}{.49\textwidth}
					\centering
					\includegraphics[width=.99\linewidth]{img1/cb100_2_2.png}  
					\caption{$ L=2, R=2 $}
					\label{fig:sub-first2}
				\end{subfigure}
				\begin{subfigure}{.49\textwidth}
					\centering
					\includegraphics[width=.99\linewidth]{img1/cb100_2_4.png}  
					\caption{$ L=2, R=4 $}
					\label{fig:sub-second2}
				\end{subfigure}
				\caption{Codebook vs Training Set for "All Audio" Training Set}
				\label{fig:fig100}
			\end{figure}
			We can see the clearly larger codebook size for $ R=4 $, which why it is more adequate.
		
		\subsection{Choosing a Training Set}
			\begin{enumerate}
				\item Training Time: Mostly dependent on the amount of data we get the training set from, fastest: "AllAudio".
				\item Training Distortion: $ D_{Audio}> D_{A+M} > D_{SayN} $.
				\item Encoding Time: No significant differences
				\item Encoding Distortion: $  D_{Audio} > D_{SayNada} > D_{A+M} $
				\item Final SNR: SNR$_{Audio} <$ SNR$_{SayNada} <$ SNR$_{A+M} $
			\end{enumerate}
			
			We can although disregard training time due to being a one time only computation.
			For a fast usage we would choose the "All Audio" training set.
			To have the best SNR, the clear choice is the biggest training set, i.e. the "All Audio and Music" training set.
				
	
	\section{Conclusions}
		\begin{itemize}
			\item Using music as a training set is clearly superior when we will use the codebook to encode music files. Vice-versa is also valid, although less significantly. Encoding both audio files from the DataSet using "All audio" as training set produces in average half the distortion.
			\item The best scenario and training set combination regarding SNR is $ L=2, R=2 $, "All Audio and Music". This combination is also the slowest to encode.
			\item Encoding time is proportional to the rate $R$ and the audio file duration.
			\item Final SNR depends on the codebook size $  K $ but has a negative effect when increasing the codevector length $ L $. The rule of thumb SNR $\approx 6 R  \ (dB)$ applies when $ L =2 $. For $ L=4 $, SNR$_{(R=1)} = 11.25 > 6 \ (dB) $ and SNR$_{(R=2)} = 19.19 > 12 \ (dB)$.
		\end{itemize}
		
		\subsection{Possible future work}
			Given more time to do further tests, one could test the influence of the $ \epsilon $ value, decreasing it should give us better results but slower convergence. 
			Normalizing the duration of encoding objects and the size of training sets could help us understand better if there are other important parameters that can change the final performance of this encoding technique.
		
\end{document}



